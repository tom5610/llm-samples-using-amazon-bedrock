{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Registration Notebook\n",
    "\n",
    "> The notebook can be run on Cloud environment (e.g. EC2 instance, SageMaker notebook, Studio notebook, etc.) with proper IAM permissions to operate on Bedrock, S3, DynamoDB, and STS. For learning more details, please referto the reference section.\n",
    "\n",
    "The purpose of the notebook is to generate synthetic data, then upload to s3, and create the DynamoDB records, which are the batch registration records.\n",
    "\n",
    "***Hold on***, what's the problem we are trying to solve? If you are not sure, please have a look at [The Problem](../README.md#the-problem)\n",
    "\n",
    "## Before running the notebook\n",
    "\n",
    "Please refer to the [README.md](../solution/README.md) to setup the AWS environment and deploy the stack. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are running at local environment, please setup aws credentials first. \n",
    "\n",
    "e.g.\n",
    "```bash\n",
    "aws configure\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env AWS_DEFAULT_REGION=us-east-1\n",
    "\n",
    "# uncomment the following line if you are running at local environment, and setup a right profile name\n",
    "# %env AWS_PROFILE=default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock = boto3.client('bedrock')\n",
    "\n",
    "bedrock_runtime = boto3.client('bedrock-runtime')\n",
    "\n",
    "model_id = 'amazon.titan-embed-text-v2:0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample text content is sourced from [What can I do with Amazon Bedrock?](https://docs.aws.amazon.com/bedrock/latest/userguide/what-is-bedrock.html#servicename-feature-overview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create some random content for sampling text content on synthetic data generation.\n",
    "free_text = \"\"\"\n",
    "What can I do with Amazon Bedrock?\n",
    "\n",
    "You can use Amazon Bedrock to do the following:\n",
    "\n",
    "Experiment with prompts and configurations – Submit prompts and generate responses with model inference by sending prompts using different configurations and foundation models to generate responses. You can use the API or the text, image, and chat playgrounds in the console to experiment in a graphical interface. When you're ready, set up your application to make requests to the InvokeModel APIs.\n",
    "\n",
    "Augment response generation with information from your data sources – Create knowledge bases by uploading data sources to be queried in order to augment a foundation model's generation of responses.\n",
    "\n",
    "Create applications that reason through how to help a customer – Build agents that use foundation models, make API calls, and (optionally) query knowledge bases in order to reason through and carry out tasks for your customers.\n",
    "\n",
    "Adapt models to specific tasks and domains with training data – Customize an Amazon Bedrock foundation model by providing training data for fine-tuning or continued-pretraining in order to adjust a model's parameters and improve its performance on specific tasks or in certain domains.\n",
    "\n",
    "Improve your FM-based application's efficiency and output – Purchase Provisioned Throughput for a foundation model in order to run inference on models more efficiently and at discounted rates.\n",
    "\n",
    "Determine the best model for your use case – Evaluate outputs of different models with built-in or custom prompt datasets to determine the model that is best suited for your application.\n",
    "\n",
    "Prevent inappropriate or unwanted content – Use guardrails to implement safeguards for your generative AI applications.\n",
    "\n",
    "Optimize your FM's latency – Get faster response times and improved responsiveness for AI applications with Latency-optimized inference for foundation models.\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthesize data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the sample text length\n",
    "sample_text_length = 150\n",
    "\n",
    "# split the free text into words\n",
    "words = free_text.split()\n",
    "print(f\"words count: {len(words)}\")\n",
    "\n",
    "# assert the words count is greater than the sample text length\n",
    "assert len(words) > sample_text_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# define the record count\n",
    "record_count = 2500\n",
    "\n",
    "# initialize the records list\n",
    "records = []\n",
    "\n",
    "# generate the records\n",
    "for i in range(record_count):\n",
    "    random_words = random.sample(words, sample_text_length)\n",
    "    random_text = ' '.join(random_words)\n",
    "    records.append(random_text)\n",
    "\n",
    "print(f\"records count for a data file: {len(records)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output `jsonl` file for batch inference job. \n",
    "\n",
    "to get more information about jsonline format, please refer to the target FM inference parameters and responses - [Amazon Titan Embeddings Text](https://docs.aws.amazon.com/bedrock/latest/userguide/model-parameters-titan-embed-text.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'synthetic-data.jsonl'\n",
    "\n",
    "# write the records to the output file\n",
    "with open(output_file, 'w') as f:\n",
    "    for i, record in enumerate(records):\n",
    "\n",
    "        output = {\n",
    "            \"recordId\": str(i), \n",
    "            \"modelInput\": {\n",
    "                \"inputText\": record,\n",
    "                \"dimensions\": 256 # 256, 512, or 1024 (default)\n",
    "            }\n",
    "        }\n",
    "        f.write(json.dumps(output) + '\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "construct the target s3 bucket name. (the naming pattern is `embedding-batch-job-{account_id}-{region_code}` per our CDK implemetation.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_name = \"SolutionStack\"\n",
    "\n",
    "# get the role arn from the stack output\n",
    "cfn_client = boto3.client('cloudformation')\n",
    "\n",
    "def get_stack_output(stack_name, output_key):\n",
    "    response = cfn_client.describe_stacks(StackName=stack_name)\n",
    "    outputs = response['Stacks'][0]['Outputs']\n",
    "\n",
    "    # Find the role ARN from the outputs\n",
    "    output_value = None\n",
    "    for output in outputs:\n",
    "        if output['OutputKey'] == output_key:  # Adjust this key based on your CDK output\n",
    "            output_value = output['OutputValue']\n",
    "            break\n",
    "\n",
    "    return output_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = get_stack_output(stack_name, \"DataS3BucketName\")\n",
    "data_uri_prefix = f\"s3://{bucket_name}/input\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total batches to be processed\n",
    "BATCH_COUNT = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "# initialize the data file uris list\n",
    "data_file_uris = []\n",
    "\n",
    "# copy the synthetic data to the target s3 bucket on each batch\n",
    "# please prepare the real data files for your use case if any.\n",
    "for i in range(BATCH_COUNT):\n",
    "    batch_id = str(uuid.uuid4())[:12]\n",
    "    input_file_uri = f\"{data_uri_prefix}/{batch_id}/data.jsonl\"\n",
    "    data_file_uris.append(input_file_uri)\n",
    "    !aws s3 cp ./$output_file $input_file_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Batch registry records in the dynamodb table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dynamodb_table_name = get_stack_output(stack_name, \"BatchRegistryTableName\")\n",
    "dynamodb_table_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from datetime import timezone\n",
    "\n",
    "dynamodb = boto3.client('dynamodb')\n",
    "\n",
    "# Get current timestamp\n",
    "current_time = datetime.now(timezone.utc).isoformat()\n",
    "\n",
    "# Store each data file URI in DynamoDB\n",
    "for uri in data_file_uris:\n",
    "    item = {\n",
    "        'data_s3_uri': {'S': uri},\n",
    "        'created_dt': {'S': current_time},\n",
    "        'status': {'S': 'Pending'},\n",
    "        'id': {'S': uri.split('/')[-2]}  # Extract batch_id from URI\n",
    "    }\n",
    "    \n",
    "    dynamodb.put_item(\n",
    "        TableName=dynamodb_table_name,\n",
    "        Item=item\n",
    "    )\n",
    "\n",
    "print(f\"Stored {len(data_file_uris)} records in DynamoDB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query the pending records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from boto3.dynamodb.conditions import Key\n",
    "\n",
    "# query the pending records\n",
    "table = boto3.resource('dynamodb').Table(dynamodb_table_name)\n",
    "response = table.query(\n",
    "    IndexName='status-index',\n",
    "    KeyConditionExpression=Key('status').eq('Pending')\n",
    ")\n",
    "\n",
    "response['Items']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference\n",
    "\n",
    "> **Note**: You don't need to run the below code cells. The below are just for reference.\n",
    "\n",
    "#### Create Batch Inference Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "role_arn = get_stack_output(stack_name, \"BatchInferenceRoleArn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_uri = data_file_uris[0]\n",
    "\n",
    "output_data_uri = f\"s3://{bucket_name}/output/\"\n",
    "\n",
    "inputDataConfig=({\n",
    "    \"s3InputDataConfig\": {\n",
    "        \"s3Uri\": input_file_uri\n",
    "    }\n",
    "})\n",
    "\n",
    "outputDataConfig=({\n",
    "    \"s3OutputDataConfig\": {\n",
    "        \"s3Uri\": output_data_uri\n",
    "    }\n",
    "})\n",
    "\n",
    "response=bedrock.create_model_invocation_job(\n",
    "    roleArn=role_arn,\n",
    "    modelId=model_id,\n",
    "    jobName=\"sample-batch-job\" + str(uuid.uuid4())[:12],\n",
    "    inputDataConfig=inputDataConfig,\n",
    "    outputDataConfig=outputDataConfig\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reference realtime inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input = {\n",
    "    \"inputText\": free_text,\n",
    "    \"dimensions\": 256,\n",
    "    \"normalize\": True\n",
    "}\n",
    "body = json.dumps(sample_input)\n",
    "response = bedrock_runtime.invoke_model(\n",
    "    modelId=model_id,\n",
    "    body=body,\n",
    "    accept='application/json',\n",
    "    contentType='application/json'\n",
    ")\n",
    "\n",
    "response_body = json.loads(response.get('body').read())\n",
    "embeddings = response_body['embedding']\n",
    "print(f\"embedding lenght: {len(embeddings)}\")\n",
    "print(f\"embedding: {embeddings}\")\n",
    "pprint(f\"response body: {response_body}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aws-demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
