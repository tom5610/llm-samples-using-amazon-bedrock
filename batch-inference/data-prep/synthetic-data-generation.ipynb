{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env AWS_DEFAULT_REGION=us-east-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_permit_text = \"\"\"\n",
    "Commencement – Breach of registered restrictive covenant\n",
    "This permit will not come into effect until the covenant contained in Instrument of Transfer [insert details] in the Register of Titles is removed or varied to avoid a breach of the covenant by this permit\n",
    "Include in any permit where the grant of the permit would authorise anything that would result in a breach of a registered restrictive covenant Mandatory condition required by Planning and Environment Act 1987 section 62(1)(aa\n",
    "Expiry – Development\n",
    "This permit as it relates to development (buildings and works) will expire if one of the following circumstances applies: a) The development is not started within 2 years of the issued date of this permit. b) The development is not completed within 4 years of the issued date of this permit. In accordance with Section 69 of the Planning and Environment Act 1987, an application may be submitted to the responsible authority for an extension of the periods referred to in this condition\n",
    "Include in all permits for development for buildings and works with appropriate modification to time for starting and completion. Where development is to be undertaken in stages, include additional conditions stating when each stage of development is to be started and completed. See chapter 6.2.1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock = boto3.client('bedrock')\n",
    "\n",
    "bedrock_runtime = boto3.client('bedrock-runtime')\n",
    "\n",
    "model_id = 'amazon.titan-embed-text-v2:0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### on-demand invoke embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input = {\n",
    "    \"inputText\": build_permit_text,\n",
    "    \"dimensions\": 256,\n",
    "    \"normalize\": True\n",
    "}\n",
    "body = json.dumps(sample_input)\n",
    "response = bedrock_runtime.invoke_model(\n",
    "    modelId=model_id,\n",
    "    body=body,\n",
    "    accept='application/json',\n",
    "    contentType='application/json'\n",
    ")\n",
    "\n",
    "response_body = json.loads(response.get('body').read())\n",
    "embeddings = response_body['embedding']\n",
    "print(f\"embedding lenght: {len(embeddings)}\")\n",
    "print(f\"embedding: {embeddings}\")\n",
    "print(f\"response body: {response_body}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthesize data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_count = build_permit_text.split()\n",
    "print(f\"words count: {len(words_count)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text_length = 150\n",
    "\n",
    "assert len(words_count) > sample_text_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "record_count = 101\n",
    "records = []\n",
    "\n",
    "for i in range(record_count):\n",
    "    random_words = random.sample(words_count, sample_text_length)\n",
    "    random_text = ' '.join(random_words)\n",
    "    records.append(random_text)\n",
    "\n",
    "print(f\"records count: {len(records)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output `jsonl` file for batch inference job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'synthetic-data.jsonl'\n",
    "with open(output_file, 'w') as f:\n",
    "    for i, record in enumerate(records):\n",
    "        output = {\n",
    "            \"recordId\": str(i), \n",
    "            \"modelInput\": {\n",
    "                \"inputText\": record,\n",
    "                \"dimensions\": 256,\n",
    "                \"embeddingsByType\": \"float\"\n",
    "            }\n",
    "        }\n",
    "        f.write(json.dumps(output) + '\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sts_client = boto3.client(\"sts\")\n",
    "response = sts_client.get_caller_identity()\n",
    "account_id = response[\"Account\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_code = boto3.session.Session().region_name\n",
    "region_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = f\"embedding-batch-job-{account_id}-{region_code}\"\n",
    "data_uri_prefix = f\"s3://{bucket_name}/input\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Batch Job Testing\n",
    "\n",
    "Create the batch files, then upload to S3, and create the DynamoDB records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "data_file_uris = []\n",
    "for i in range(batches):\n",
    "    batch_id = str(uuid.uuid4())[:8]\n",
    "    input_file_uri = f\"{data_uri_prefix}/{batch_id}/data.jsonl\"\n",
    "    data_file_uris.append(input_file_uri)\n",
    "    !aws s3 cp ./$output_file $input_file_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_uris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from datetime import timezone\n",
    "\n",
    "dynamodb = boto3.client('dynamodb')\n",
    "\n",
    "# Get current timestamp\n",
    "current_time = datetime.now(timezone.utc).isoformat()\n",
    "\n",
    "# Store each data file URI in DynamoDB\n",
    "for uri in data_file_uris:\n",
    "    item = {\n",
    "        'data_s3_uri': {'S': uri},\n",
    "        'created_dt': {'S': current_time},\n",
    "        'status': {'S': 'Pending'},\n",
    "        'id': {'S': uri.split('/')[-2]}  # Extract batch_id from URI\n",
    "    }\n",
    "    \n",
    "    dynamodb.put_item(\n",
    "        TableName='embedding-batch-registry',\n",
    "        Item=item\n",
    "    )\n",
    "\n",
    "print(f\"Stored {len(data_file_uris)} records in DynamoDB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from boto3.dynamodb.conditions import Key\n",
    "\n",
    "table = boto3.resource('dynamodb').Table(\"embedding-batch-registry\")\n",
    "response = table.query(\n",
    "    IndexName='status-index',\n",
    "    KeyConditionExpression=Key('status').eq('Pending')\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference\n",
    "\n",
    "#### Create Batch Inference Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "iam_role_arn = f\"arn:aws:iam::{account_id}:role/SolutionStack-BedrockBatchJobRole98C7DFA0-iyjwcI9nLVu3\"\n",
    "\n",
    "input_file_uri = f\"s3://{bucket_name}/batch/input/synthetic-data-50k.jsonl\"\n",
    "\n",
    "output_data_uri = f\"s3://{bucket_name}/batch-inference/embedding/building/output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputDataConfig=({\n",
    "    \"s3InputDataConfig\": {\n",
    "        \"s3Uri\": input_file_uri\n",
    "    }\n",
    "})\n",
    "\n",
    "outputDataConfig=({\n",
    "    \"s3OutputDataConfig\": {\n",
    "        \"s3Uri\": output_data_uri\n",
    "    }\n",
    "})\n",
    "\n",
    "response=bedrock.create_model_invocation_job(\n",
    "    roleArn=iam_role_arn,\n",
    "    modelId=model_id,\n",
    "    jobName=\"building-text-embedding-batch-job-002\",\n",
    "    inputDataConfig=inputDataConfig,\n",
    "    outputDataConfig=outputDataConfig\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_batch_inference_jobs(status_list: list[str]=[\"Submitted\", \"Validating\", \"Scheduled\", \"InProgress\", \"Stopping\"], name_contains: str=\"building-text-embedding\"):\n",
    "    \"\"\"\n",
    "    Get batch inference jobs by status and name contains.\n",
    "    \n",
    "    \"\"\"\n",
    "    if not status_list:\n",
    "        return []\n",
    "    next_token = None\n",
    "    invocations = []\n",
    "    while True:\n",
    "        if next_token is None:\n",
    "            res = bedrock.list_model_invocation_jobs(\n",
    "                nameContains=name_contains,\n",
    "            )\n",
    "        else:\n",
    "            res = bedrock.list_model_invocation_jobs(\n",
    "                nameContains=name_contains,\n",
    "                nextToken=next_token\n",
    "            )\n",
    "            \n",
    "        invocations.extend(res.get(\"invocationJobSummaries\"))\n",
    "        if \"nextToken\" in res: \n",
    "            next_token = res.get(\"nextToken\")\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return [inv for inv in invocations if inv.get(\"status\") in status_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = get_batch_inference_jobs()\n",
    "\n",
    "pprint(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from datetime import timezone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.now(timezone.utc).isoformat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aws-demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
